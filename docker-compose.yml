services:
  app:
    build: .
    image: assistant-ai:latest
    container_name: assistant-ai-app
    restart: unless-stopped
    environment:
      GRPC_ADDR: "0.0.0.0:50051"
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      # LLM API keys (set in .env file)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      # For local models (Ollama, LocalAI, etc.)
      # macOS/Windows: use host.docker.internal instead of localhost
      # Example: http://host.docker.internal:11434/v1
      OPENAI_BASE_URL: ${OPENAI_BASE_URL:-}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-3.5-turbo}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
    ports:
      - "50052:50051"
    # Enable access to host machine from container
    # macOS/Windows: host.docker.internal is automatically available
    # Linux: may need to add extra_hosts: ["host.docker.internal:host-gateway"]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - assistant-net

  redis:
    image: redis:7-alpine
    container_name: assistant-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis-data:/data
    networks:
      - assistant-net
    healthcheck:
      test: ["CMD", "sh", "-c", "redis-cli -a ${REDIS_PASSWORD:-redis123} ping | grep -q PONG"]
      interval: 10s
      timeout: 3s
      retries: 3

volumes:
  redis-data:
    driver: local

networks:
  # Reuse the network from assistant_account
  assistant-net:
    name: assistant_assistant-net
    external: true

